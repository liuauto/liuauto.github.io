<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=iso-8859-1">
<title>l1_logreg: l1_logreg: A large-scale solver for l1-regularized logistic regression problems</title>
<link href="stylesheet.css" rel="stylesheet" type="text/css">
<link href="tabs.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.5.5 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul>
      <li class="current"><a href="index.html"><span>Main&nbsp;Page</span></a></li>
      <li><a href="pages.html"><span>Related&nbsp;Pages</span></a></li>
      <li><a href="annotated.html"><span>Data&nbsp;Structures</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
</div>
<div class="contents">
<h1>l1_logreg: A large-scale solver for l1-regularized logistic regression problems</h1>
<p>
<h3 class="centered">0.8.2 </h3>
<p>
<h3 class="centered"><a href="http://www.stanford.edu/~deneb1">Kwangmoo Koh</a>, <a href="http://www.stanford.edu/~sjkim">Seung-Jean Kim</a>, and <a href="http://www.stanford.edu/~boyd">Stephen Boyd</a> </h3>
<h2><a class="anchor" name="idx">
Table of contents</a></h2>
<ul>
<li>
<a class="el" href="index.html#introduction">Introduction</a> </li>
<li>
<a class="el" href="index.html#install">Installation</a> </li>
<li>
<a class="el" href="index.html#download">Download</a> </li>
<li>
<a class="el" href="index.html#usage">Usage</a> </li>
<li>
<a class="el" href="fileformat.html">File format</a> </li>
<li>
<a class="el" href="index.html#example">Example</a> </li>
</ul>
<h2><a class="anchor" name="introduction">
Introduction</a></h2>
<code>l1_logreg</code> is an implementation of the interior-point method for l1-regularized logistic regression described in the paper, <a href="http://www.stanford.edu/~boyd/l1_logistic_reg.html">An Interior-Point Method for Large-Scale l1-Regularized Logistic Regression</a>. This implementation consists of three main functions: <ul>
<li>
<code>l1_logreg_train</code> for training </li>
<li>
<code>l1_logreg_classify</code> for classification </li>
<li>
<code>l1_logreg_regpath</code> for (approximate) regularization path computation </li>
</ul>
<p>
<code>l1_logreg</code> concerns the <em>logistic model</em> that has the form <p class="formulaDsp">
<img class="formulaDsp" alt="\[ \mbox{Prob}(b|x) = \frac{\exp(b(w^Tx+v))}{1+\exp(b(w^Tx+v))}, \]" src="form_0.png">
<p>
 where <img class="formulaInl" alt="$x\in\mathbf{R}^n$" src="form_1.png"> denotes a vector of feature variables, and <img class="formulaInl" alt="$b\in\{-1,+1\}$" src="form_2.png"> denotes the associated binary outcome (class). Here, <img class="formulaInl" alt="$\mbox{Prob}(b|x)$" src="form_3.png"> is the conditional probability of <img class="formulaInl" alt="$b$" src="form_4.png">, given <img class="formulaInl" alt="$x$" src="form_5.png">. The logistic model has parameters <img class="formulaInl" alt="$v\in\mathbf{R}$" src="form_6.png"> (the intercept) and <img class="formulaInl" alt="$w\in\mathbf{R}^n$" src="form_7.png"> (the weight vector).<p>
With a given set of training examples, <p class="formulaDsp">
<img class="formulaDsp" alt="\[ (x_i,b_i)\in \mathbf{R}^n \times \{-1,+1\},~i=1,\ldots,m, \]" src="form_8.png">
<p>
 <code>l1_logreg_train</code> finds the logistic model by solving an optimization problem of the form <p class="formulaDsp">
<img class="formulaDsp" alt="\[ \begin{array}{ll}\mbox{minimize} &amp; (1/m)\sum_{i=1}^m \log\left(1+\exp(-b_i(x_i^Tw+v))\right) + \lambda \sum_{i=1}^n |w_i|, \end{array} \]" src="form_9.png">
<p>
 where the variables are <img class="formulaInl" alt="$w \in \mathbf R^n$" src="form_10.png">, <img class="formulaInl" alt="$v \in \mathbf R$" src="form_11.png">, and the problem data are <img class="formulaInl" alt="$x_i$" src="form_12.png">, <img class="formulaInl" alt="$b_i$" src="form_13.png"> and <img class="formulaInl" alt="$\lambda >0$" src="form_14.png">. We refer to the problem as a <em><img class="formulaInl" alt="$l_1$" src="form_15.png">-regularized logistic regression problem</em> (l1-regularized LRP).<p>
Once we find maximum likelihood values of <img class="formulaInl" alt="$v$" src="form_16.png"> and <img class="formulaInl" alt="$w$" src="form_17.png">, <em>i.e.</em>, a solution of the l1-regularized LRP, we can predict the probability of the two possible outcomes, <img class="formulaInl" alt="$\mbox{Prob}(\pm 1|x)$" src="form_18.png">, given a new feature vector <img class="formulaInl" alt="$x\in\mathbf{R}^n$" src="form_1.png">, using the associated logistic model.<p>
<code>l1_logreg_classify</code> performs classification over a (test) data set <img class="formulaInl" alt="$ \{\tilde{x}_i\in\mathbf{R}^n:~i=1,\ldots,\tilde{m}\}$" src="form_19.png"> by computing <p class="formulaDsp">
<img class="formulaDsp" alt="\[ \hat{b}_i = \mbox{sgn}\left(\tilde{x}_i^Tw+v\right),\quad~i=1,\ldots,\tilde{m}, \]" src="form_20.png">
<p>
 which picks the more likely outcome, given <img class="formulaInl" alt="$x_i$" src="form_12.png">, according to the logistic model found by <code>l1_logreg_train</code>. <p>
The regularization parameter <img class="formulaInl" alt="$\lambda$" src="form_21.png"> roughly controls the number of nonzero components in <img class="formulaInl" alt="$w$" src="form_17.png">, with larger <img class="formulaInl" alt="$\lambda$" src="form_21.png"> typically yielding sparser <img class="formulaInl" alt="$w$" src="form_17.png">. The family of solutions, as <img class="formulaInl" alt="$\lambda$" src="form_21.png"> varies over <img class="formulaInl" alt="$(0,\infty)$" src="form_22.png"> is called the <em>regularization path</em>. <code>l1_logreg_regpath</code> finds an approximate regularization path efficiently using a warmstart technique.<p>
To solve the l1-regularized LRP, <code>l1_logreg</code> uses Preconditioned Conjugate Gradient (PCG) method if the feature matrix is stored in sparse format, and the direct method if the feature matrix is stored in dense format. For more information on file format, see <a class="el" href="fileformat.html">file format</a> page.<h3><a class="anchor" name="features">
Features</a></h3>
<code>l1_logreg</code> <ul>
<li>
can handle both dense and sparse problems. </li>
<li>
can handle large-scale (sparse) problems (with a million features and examples). </li>
<li>
supports various external <a class="el" href="library.html">BLAS and LAPACK libraries</a> (ATLAS, MKL, ACML and so on). </li>
<li>
can apply standardization to sparse data efficiently. </li>
</ul>
<h3><a class="anchor" name="howtouse">
How to use the package</a></h3>
You can use the package in different ways. <ul>
<li>
The easiest method is to use the stand-alone executables <code>l1_logreg_train</code>, <code>l1_logreg_classify</code> and <code>l1_logreg_regpath</code> in the command line. See <a class="el" href="index.html#usageshell">using l1_logreg in shell</a> section. </li>
<li>
Write a C-program that calls the function <code>l1_logreg_train</code> and <code>l1_logreg_train</code> in <code><a class="el" href="l1__logreg_8c.html" title="Main source file for l_1-regularized logistic regression problem solver.">src_c/l1_logreg.c</a></code>. </li>
<li>
It is also callable from Matlab, using Matlab system call. See <a class="el" href="index.html#usagematlab">using l1_logreg in Matlab</a> section. </li>
<li>
We hope to add an R interface soon. </li>
</ul>
<h2><a class="anchor" name="install">
Installation</a></h2>
To use <code>l1_logreg</code>, you need to get executables compatible with your machine. You may download precompiled executables or download the source code to build your own.<p>
To install precompiled executables, you can simply download executables compatible with your OS and CPU.<p>
If your cannot find appropriate binaries for your machine, follow the instructions in <a class="el" href="srcbuild.html">build-your-own</a> section.<p>
If you have trouble in configuration or compilation, see <a class="el" href="stepbystep.html">step-by-step installation</a> or check <a class="el" href="faq.html">FAQ</a>.<h2><a class="anchor" name="download">
Download</a></h2>
<code>l1_logreg</code> is distributed under the terms of the <a href="http://www.gnu.org/copyleft/gpl.html">GNU General Public License 2.0</a>. For commercial applications that may be incompatible with this license, please do not hesitate to contact us to discuss alternatives.<p>
To obtain the <code>l1_logreg</code> distribution, which includes the source code, the manual, and example data sets, use the following links: <ul>
<li>
Source package: <a href="download/l1_logreg-0.8.2.tar.gz">l1_logreg-0.8.2.tar.gz (352K)</a> </li>
</ul>
<p>
If you just want binaries, you can download them from the following links: <ul>
<li>
Binaries for Intel/AMD Linux: <a href="download/l1_logreg-0.8.2-i686-pc-linux-gnu.tar.gz">l1_logreg-0.8.2-i686-pc-linux-gnu.tar.gz (2.4M)</a> </li>
<li>
Binaries for Intel MAC OS X (10.5): <a href="download/l1_logreg-0.8.2-i686-apple-darwin9.7.0.tar.gz">l1_logreg-0.8.2-i686-apple-darwin9.7.0.tar.gz (88K)</a> </li>
</ul>
<p>
If you want to run examples, download and untar the source package first, and put the executables in the binary package at <code>src_c</code> directory. For test, run <code>test_script</code> at the top-build directory of source package after putting/making the binaries in <code>src_c</code> directory.<p>
NOTE: The pre-compiled binaries would be slow. To achieve maximum performance you might want to compile the source code using BLAS appropriate to your own machine.<p>
Before installation, be sure that BLAS and LAPACK libraries are installed in your machine. If not (or not sure), please check the <a class="el" href="library.html">libraries</a> page.<h2><a class="anchor" name="usage">
Usage</a></h2>
<h3><a class="anchor" name="usageshell">
Using l1_logreg in shell</a></h3>
Typical usage of <code>l1_logreg_train</code> is: <pre class="shell">
<span class="cmd">l1_logreg_train -s train_x train_b 0.01 model</span>
</pre> It performs training, that is learning a logistic model from training examples of feature matrix <code>train_x</code> and class vector <code>train_b</code> with <img class="formulaInl" alt="$\lambda$" src="form_21.png">= 0.01. The model learned from example data are stored in <code>model</code>.<p>
Typical usage of <code>l1_logreg_classify</code> is: <pre class="shell">
<span class="cmd">l1_logreg_classify model test_x result</span>
</pre> It classifies the test data using the logistic model parameters stored in <code>model</code> and store the classification result to <code>result</code> file. If you want to not only classify the test data, but also compare the result with a known class vector <code>test_b</code>, use the <code>-t</code> option: <pre class="shell">
<span class="cmd">l1_logreg_classify -t test_b model test_x results</span>
</pre><h3><a class="anchor" name="usagematlab">
Using l1_logreg in Matlab</a></h3>
<code>l1_logreg</code> is callable from Matlab. You may write the problem data (feature matrix and class vector) first using <code>mmwrite</code> script; see <a class="el" href="fileformat.html#matlabmm">writing matrices in Matrix Market (MM) format using Matlab</a> page. You may call stand-alone executables using Matlab <code>system</code> call. For example, <pre class="matlab">
<span class="cmd">mmwrite('ex_X',X);</span>
<span class="cmd">mmwrite('ex_b',b);</span>
<span class="cmd">system('l1_logreg_train -s ex_X ex_b 0.01 model_iono')</span>
<span class="result">...</span>
<span class="cmd">model_iono = mmread('model_iono');</span>
</pre> You may assign the result file to a Matlab variable using <code>mmread</code> script. For example, <pre class="matlab">
<span class="cmd">system('l1_logreg_classify -t ex_b model_iono ex_X result_iono')</span>
<span class="result">...</span>
<span class="cmd">model_iono = mmread('result_iono');</span>
</pre><h3><a class="anchor" name="calltrain">
Calling sequence for training</a></h3>
Calling sequence for <code>l1_logreg_train</code> is <pre>
l1_logreg_train [options] feature_file class_file lambda model_file
</pre> Arguments are <pre>
    feature_file        - feature matrix
    class_file          - output vector
    lambda              - regularization parameter
    model_file          - store model data to file model_file
</pre> Options are <pre>
    -q                  - quiet mode
    -v [0..3]           - set verbosity level (default 1)
                            0 : show one line summary
                            1 : show simple log
                            3 : show detailed log
    -r                  - use relative lambda
                            if used,     lambda := lambda*lambda_max
                            if not used, lambda := lambda
    -s                  - standardize data
</pre> Advanced options are <pre>
    -h                  - show coefficients histogram and trim
    -k &lt;double&gt;         - set tolerance for zero coefficients from KKT
                          condition
    -t &lt;double&gt;         - set tolerance for duality gap
</pre><p>
See <a class="el" href="fileformat.html">file format</a> page for the formats of <code>feature_file</code>, <code>class_file</code> and <code>out_file</code>.<h3><a class="anchor" name="callclass">
Calling sequence for classification</a></h3>
Calling sequence for <code>l1_logreg_classify</code> is: <pre>
l1_logreg_classify [options] model_file feature_file result_file
</pre> Arguments are: <pre>
    model_file          - model data(coefficients and intercept)
                          found by either l1_logreg_train or
                          l1_logreg_regpath
    feature_file        - feature matrix
    result_file         - store classification results to result_file
                          if model_file is generated from
                           1) l1_logreg_train, then predicted outcomes
                           2) l1_logreg_regpath, then the number of errors
                          will be stored.
</pre> Options are: <pre>
    -q                  - quiet mode
    -p                  - store probability instead of predicted outcome
    -t &lt;class_file&gt;     - test classification result
                          against real class vector in &lt;class_file&gt;
</pre><p>
See <a class="el" href="fileformat.html">file format</a> page for the formats of <code>feature_file</code>, <code>class_file</code> and <code>out_file</code>.<h3><a class="anchor" name="callregpath">
Calling sequence for regularization path computation</a></h3>
Calling sequence for <code>l1_logreg_regpath</code> is: <pre>
l1_logreg_regpath [options] feature_file class_file lambda_min num_lambda model_file
</pre> Arguments are: <pre>
    feature_file        - feature matrix
    class_file          - output vector
    lambda_min          - minimum value of regularization parameter
    num_lambda          - number of lambdas (sample)
    model_file          - store results to file model_file
</pre> Options are: <pre>
    -c                  - only coefficients (to know real coefficients).
                          The model_file generated with -c option cannot
                          be used for classification.
                          Use this option only to plot regularization path.
    -q                  - quiet mode
    -v [0..3]           - set verbosity level
                            0 : show one line summary
                            1 : show simple log
                            3 : show detailed log
    -r                  - use relative lambda
                            if used,     lambda := lambda*lambda_max
                            if not used, lambda := lambda
    -s                  - standardize data
</pre> Advanced options are <pre>
    -k &lt;double&gt;         - set tolerance for zero coefficients from KKT
                          condition
    -t &lt;double&gt;         - set tolerance for duality gap
</pre><p>
See <a class="el" href="fileformat.html">file format</a> page for the formats of <code>feature_file</code>, <code>class_file</code> and <code>out_file</code>.<h2><a class="anchor" name="example">
Example</a></h2>
<ul>
<li>
<a class="el" href="index.html#extraining">Training</a> </li>
<li>
<a class="el" href="index.html#exclassification">Classification</a> </li>
<li>
<a class="el" href="index.html#exregpath">Regularization path computation</a> </li>
</ul>
<h3><a class="anchor" name="extraining">
Training</a></h3>
Consider a small problem with 3 examples and 4 features: <code> <pre>
           feature 1   feature 2   feature 3   feature 4       class
example 1      3           0           1          -2             1
example 2      0           0           2           5            -1
example 3      7           1          -4           0             1
</pre> </code><p>
To solve associated l1-regularized LRP, a user stores a feature matrix and a class vector in MM format. Feature matrix can be stored in either array (dense) format and coordinate (sparse) format. If the problem is stored in dense format, <code>l1_logreg_train</code> uses direct methods. If stored in sparse format, <code>l1_logreg_train</code> uses the PCG method in solving the problem.<p>
The associated feature matrix can be stored in the file <code>train_x</code> in dense format. <pre class="filename"><span>train_x</span></pre> <pre class="file">
%%MatrixMarket matrix array real general
3 4
 3
 0
 7
 0
 0
 1
 1
 2
-4
-2
 5
 0
</pre> The associated feature matrix can be stored in the file <code>train_x</code> in sparse format. <pre class="filename"><span>train_x</span></pre> <pre class="file">
%%MatrixMarket matrix coordinate real general
3 4 8
1 1  3
3 1  7
3 2  1
1 3  1
2 3  2
3 3 -4
1 4 -2
2 4  5
</pre><p>
A class file must be stored in array (dense) format for both direct and PCG methods. <pre class="filename"><span>train_b</span></pre> <pre class="file">
%%MatrixMarket matrix array real general
3 1
 1
-1
 1
</pre><p>
To standardize training data <code>train_x</code> and to learn a model with <img class="formulaInl" alt="$\lambda=0.01$" src="form_23.png"> from the standardized training data, execute the following command: <pre class="shell">
<span class="cmd">l1_logreg_train -s train_x train_b 0.01 model</span>
</pre> This will generate the following file <code>model</code>: <pre class="filename"><span>model</span></pre> <pre class="file">
%MatrixMarket matrix array real general
%
% This is a model file of train_x,
%    generated by l1_logreg_train ver.0.8.2
% Contents of model:
%    entry 1: intercept
%    entries 2..m: coefficients
%
5 1
 1.568009374292901e+00
 4.043495151532541e-01
 0.000000000000000e+00
 0.000000000000000e+00
-1.103257200261706e+00
</pre><h3><a class="anchor" name="exclassification">
Classification</a></h3>
Consider a small test data set of 2 examples with 4 features: <pre>
           feature 1   feature 2   feature 3   feature 4
example 1      5           1           0           0   
example 2     -3           0           2           3  
</pre><p>
The test data set can be stored in the file <code>test_x</code> in dense format. <pre class="filename"><span>test_x</span></pre> <pre class="file">
%MatrixMarket matrix array real general
2 4
 5
-3
 1
 0
 0
 2
 0
 3
</pre> The test data set can be stored in the file <code>test_x</code> in sparse format. <pre class="filename"><span>test_x</span></pre> <pre class="file">
%MatrixMarket matrix coordinate real general
2 4 5
1 1  5
2 1 -3
1 2  1
2 3  2
2 4  3
</pre><p>
To classify the test data set using the logistic model stored in <code>model</code>, execute the following command: <pre class="shell">
<span class="cmd">l1_logreg_classify model test_x result</span>
</pre><p>
The classification result will be saved in the file <code>result</code>. <pre class="filename"><span>result</span></pre> <pre class="file">
%MatrixMarket matrix array real general
% 
% This is the file that stores the test result of test_x,
%    generated by l1_logreg_classify ver 0.8.2
% Each row contains a predicted class of corresponding example.
% 
2 1
         1
        -1
</pre><p>
To compare the predicted outcome which will be stored in the result file <code>result</code> with the known outcome <code>test_b</code>, write the known outcome (class) vector file <code>test_b</code> in MM format and execute the following command: <pre class="shell">
<span class="cmd">l1_logreg_classify -t test_b model test_x result</span>
</pre><h3><a class="anchor" name="exregpath">
Regularization path computation</a></h3>
To generate an approximation of the regularization path, from <img class="formulaInl" alt="$\lambda_{\max}$" src="form_24.png"> to a given <img class="formulaInl" alt="$\lambda=0.01\lambda_{\max}$" src="form_25.png">, use <pre class="shell">
<span class="cmd">l1_logreg_regpath -r train_x train_b 0.01 100 path_model</span>
</pre> It generates two files: <code>path_model</code> and <code>path_model_lambda</code>. The former contains a matrix of models whose column corresponds to the logistic model for each <img class="formulaInl" alt="$\lambda$" src="form_21.png"> value. The latter contains a vector of <img class="formulaInl" alt="$\lambda$" src="form_21.png"> values. The option <code>-r</code> is used to set <img class="formulaInl" alt="$\lambda$" src="form_21.png"> value relative to <img class="formulaInl" alt="$\lambda_{\max}$" src="form_24.png">.<p>
To apply classification to this family of models <code>path_model</code>, execute the following command: <pre class="shell">
<span class="cmd">l1_logreg_classify -t train_b path_model train_x path_result</span>
</pre> The number of examples whose prediction is wrong will be stored to a result file <code>path_result</code>. Note that the result of classification using <code>l1_logreg_regpath</code> is different from that of <code>l1_logreg_train</code>.<h3><a class="anchor" name="exdata">
Example data sets</a></h3>
<code>l1_logreg</code> contains some example data sets as well as their shell scripts in the <code>examples</code> directory. You can download more examples (including large-scale data sets) from the website of <code>l1_logreg</code>.<p>
If you have a problem in using <code>l1_logreg</code>, try <a class="el" href="faq.html">FAQ</a>.<h2><a class="anchor" name="feedback">
Feedback</a></h2>
We welcome your feedback. Please contact <a href="mailto:deneb1@stanford.edu">Kwangmoo Koh</a>&lt;<a href="mailto:deneb1@stanford.edu">deneb1@stanford.edu</a>&gt;, <a href="mailto:sjkim@stanford.edu">Seung-Jean Kim</a>&lt;<a href="mailto:sjkim@stanford.edu">sjkim@stanford.edu</a>&gt; or <a href="mailto:boyd@stanford.edu">Stephen Boyd</a>&lt;<a href="mailto:boyd@stanford.edu">boyd@stanford.edu</a>&gt; with your bug reports and suggestions.<p>
If you do send a bug report, please include the following information if possible:<p>
<ol>
<li>
The versions of <code>l1_logreg</code> and platform (OS, CPU) you are using. </li>
<li>
A copy of the error messages, if any, produced by the program. </li>
<li>
The data files that we can use to reproduce the problem. </li>
</ol>
<p>
Your help will be greatly appreciated.<h2><a class="anchor" name="ack">
Acknowledgement</a></h2>
</div>
<hr size="1"><address style="align: right;"><small>
Generated on Mon May 25 19:15:19 2009 for l1_logreg by Doxygen 1.5.5</small></address>
</body>
</html>
